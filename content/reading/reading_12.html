---
title: Adaptive Behavior and Objectives
class_date: '2018-02-19'
class_number: 12
weight: 12
slug: reading_12
pubdate: '2018-01-01'
date: '2018-02-19'
output:
  blogdown::html_page:
    md_extensions: +tex_math_single_backslash+compact_definition_lists
---



<div id="homework" class="section level2">
<h2>Homework</h2>
<p>Homework #9 is due today: Railsback &amp; Grimm, Ch. 10, Ex. 10.1, 10.2 (everyone), Ch. 11, Ex. 11.1, 11.2 (everyone), and Ch. 11, Ex. 11.3 (grad. students). See the homework assignment sheet for details.</p>
</div>
<div id="reading" class="section level2">
<h2>Reading:</h2>
<ul>
<li>Railsback &amp; Grimm, Ch. 11.</li>
</ul>
<div id="reading-notes" class="section level3">
<h3>Reading Notes:</h3>
<p>Agents’ behavior often consists of trying to achieve some <strong>objective</strong>.</p>
<p>I have discussed the way that Adam Smith’s “invisible hand of the market” is a kind of agent-based view of a nation’s economy: Each person (agent) has an objective of trying to maximize his or her own wealth (that’s the agent’s <strong>micromotive</strong>), and in doing so, the population of agents manages unintentionally to maximize the total wealth of the nation (an emergent <strong>macrobehavior</strong> that results from the collective interactions of the agents and their micromotives).</p>
<p>For Darwin, agents whose objectives are to survive and reproduce under changing environmental conditions achieve emergent phenomena of evolution and speciation.</p>
<p>If we are going to program an agent-based model to simulate such an economy (we saw this in the Sugarscape models), you need to program your agents to try to achieve their objective (maximize their wealth). There are two approaches to this:</p>
<ol style="list-style-type: decimal">
<li>You could program a sophisticated strategy into your agents.</li>
<li>You could program a simple strategy into your agents, but give them the ability to learn from their experience and adapt their behavior according to what they learn. (see section 11.3 for details and an example)</li>
</ol>
<p>This chapter discusses different kinds of objectives you might have your agents employ. An important concept from decision theory and behavioral economics that might be new to you is <strong>satisficing</strong>. This term, introduced by Herbert Simon<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> in 1956, refers to making decisions by choosing a “good-enough” option when it would take too much time and effort to determine which option is the absolute best. See section 11.4 for details and an example.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Herbert Simon (1916–2001) was a fascinating intellectual. Kind of a renaissance scholar, he made major contributions to political science, economics, cognitive psychology, and artificial intelligence. He won the Nobel Prize for economics in 1978. His publications have been cited more than 250,000 times and even fifteen years after his death, they are still cited more than 10,000 times per year.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
